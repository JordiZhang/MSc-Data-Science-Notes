First techniques to check our statistical models are graphical ones, i.e. plots. We have numerous different plots we can use, histograms, linearised frequency plots, Quantile-Quantile plots, etc...
# Goodness Of Fit
## Chi-squared Test
The idea is to compare the observed values vs the expected values from the theoretical distribution by calculating the individual squared differences and then combining them into the chi-squared test statistic:
$$X^2=\sum^n_{i=1}\frac{(O_i-E_i)^2}{E_i}$$
Essentially what we have is an aggregate of the percentage deviation of our data points from the theoretical distribution. It can then be proved that if the sample size n is large enough, then the distribution of $X^2$ follows a chi-squared distribution
$$X^2\approx \chi^2_\nu$$
where $\nu$ is the number of degrees of freedom which is equal to $n-1$ the number of data points. Note that this can also be done by first binning data into $r$ intervals and then we have $r$ data points so $\nu=r-1$. Also each estimated parameter reduces the number of degrees of freedom by one.
## Sign Test
Let $X_1, \ldots, X_n$ denote a random sample with a continuous distribution function $F(x)$. The median of $F$ is the value $m$ such that $F(m)=0.5$, i.e.
$$
\mathrm{P}\left(X_i<m\right)=0.5, \quad \mathrm{P}\left(X_i>m\right)=0.5 .
$$
Note that because the distribution is continuous, we have $\mathrm{P}\left(X_i=m\right)=0$.
Hence, the sign of each difference $X_i-m$ is, independently, negative or positive with probabilities $F(m)=0.5$ and $1-F(m)=0.5$, respectively. Hence, if we consider the indicators
$$
D_i=I_{\left\{X_i>m\right\}}= \begin{cases}1 & \text { if } X_i>m, \\ 0 & \text { otherwise },\end{cases}
$$
then $D_1, \ldots, D_n$ are independent Bernoulli random variables with parameter $p=0.5$,
$$
D_i \sim \operatorname{Ber}(0.5) \quad(i=1, \ldots, n) .
$$
Then, for testing hypotheses regarding the median $m$, it is natural to use the statistic $T=D_1+\cdots+D_n$, the total number of positive values $D_i$ in the sample. Indeed, if $m$ is the true median, we expect $T \approx n / 2$, so values $T_{o b s}$ that are "far away" from $n / 2$ would provide evidence against $m$.

More precisely, noting that $T \sim \operatorname{Bin}(n, 0.5)$ (if $m$ is a true median), probabilities of "large" deviations of $T$ from $n / 2$ can be evaluated, so we can control how likely such deviations may be, contrasting this with the observed value $T_{o b s}$.

Since the value of $T=D_1+\cdots+D_n$ depends on the signs of $D_i=X_i-m$, this test is called the sign test. Then we can do hypothesis testing on this since we know the distribution of $T$.

If a sample of size $n=200$ contains $85$ values greater than $5$ and $115$ values less than $5$, what is the $p$-value of the sign test of the hypothesis that the median is equal to $5$?

We have $T\sim Bin(200,0.5)$ and $T_{obs}=85$, hence:
$$P(T\leq85)+P(T\geq 115)=2P(T\leq 85)=0.0400$$
We can also do one tailed tests, or even paired tests where instead of comparing to a median, we compare two samples and consider the matched differences and testing the null hypothesis $m=0$.

Since the sign test relies on the binomial distribution, we can also use a normal approximation of the sign test.