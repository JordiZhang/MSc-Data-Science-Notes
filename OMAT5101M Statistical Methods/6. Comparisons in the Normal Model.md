# Comparing Means
Suppose we have two independent random samples with normal distributions $X_1,...,X_m\sim N(\mu_x,\sigma^2_x)$ and $Y_1,...,X_n\sim N(\mu_y,\sigma^2_y)$. Then we also know the sample means distributions
$$\bar{X}\sim N\left(\mu_x,\frac{\sigma^2_x}{m}\right),\qquad \bar{Y}\sim N\left(\mu_y,\frac{\sigma^2_y}{n}\right)$$
Hence we can take the difference of the means and get its respective distribution
$$\bar{X}-\bar{Y}\sim N\left(\mu_x-\mu_y,\frac{\sigma^2_x}{m}+\frac{\sigma^2_y}{n}\right)\Rightarrow \frac{\bar{X}-\bar{Y}-(\mu_x-\mu_y)}{\sqrt{\sigma^2_x/m+\sigma^2_y/n}}\sim N(0,1)$$
Since we test on the null hypothesis and regardless of its form, we will test on $\mu_x=\mu_y$, so we have
$$\frac{\bar{X}-\bar{Y}}{\sqrt{\sigma^2_x/m+\sigma^2_y/n}}\sim N(0,1)$$
## Known Variances: $z$-test
In this case both variances are known, so since we know about the normality of the difference of means we can use that directly for hypothesis testing making this case very simple.
- $H_0: \mu_x=\mu_y$ vs. $H_1: \mu_x \neq \mu_y$ :
$$
|\bar{X}-\bar{Y}|>z(\alpha / 2) \sqrt{\frac{\sigma_x^2}{m}+\frac{\sigma_y^2}{n}} \Rightarrow \text { reject } H_0
$$
- $H_0: \mu_x \leq \mu_y$ vs. $H_1: \mu_x>\mu_y$ :
$$
\bar{X}-\bar{Y}>z(\alpha) \sqrt{\frac{\sigma_x^2}{m}+\frac{\sigma_y^2}{n}} \Rightarrow \text { reject } H_0
$$
For mirror version, simply swap the $X$ and $Y$ samples.
## Unknown Equal Variances: $t$-test
If the variances are unknown, we estimate them using the sample variances. Then by Student's Theorem we have:
$$\frac{(m-1)S^2_x}{\sigma^2_x}\sim \chi^2_{m-1},\qquad \frac{(n-1)S^2_y}{\sigma^2_y}\sim \chi^2_{n-1}$$
This suggests that the $z$ test used before should be replaced by a suitable $t$-test. In the case of equal variances $\sigma^2_x=\sigma^2_y=\sigma^2$, this is true, but if they are different we will have to use a different technique as we discuss in the next section. Going back to the equal case, we can estimate $\sigma^2$ jointly from both samples by using the pooled variance estimator (unbiased estimator) 
$$S^2_p=\frac{(m-1)S^2_x+(n-1)S^2_y}{m+n-2}$$
Student's Theorem (Corollary 2) tells us that, 
$$B=\frac{(m+n-2)S^2_p}{\sigma^2}\sim \chi^2_{m+n-2}$$
The label $B$ is arbitrary and is only for illustration purposes as we will see soon. We also know that the difference of means has a normal distribution 
$$A=\frac{\bar{X}-\bar{Y}}{\sigma\sqrt{1/m+1/n}}\sim N(0,1)$$
Finally applying Student's Theorem, we know that $A$ and $B$ are independent and so we can construct a $t$-distribution
$$\widetilde{T}=\frac{A}{\sqrt{B/(m+n-2)}}=\frac{\bar{X}-\bar{Y}}{S_p\sqrt{1/m+1/n}}\sim t_{m+n-2}$$
Then hypothesis testing can be done on this $t$-distribution we have constructed.
- $H_0: \mu_x=\mu_y$ vs. $H_1: \mu_x \neq \mu_y$ :
$$
|\bar{X}-\bar{Y}|>t_{m+n-2}(\alpha / 2) S_p \sqrt{\frac{1}{m}+\frac{1}{n}} \Rightarrow \text { reject } H_0
$$
- $H_0: \mu_x \leq \mu_y$ vs. $H_1: \mu_x>\mu_y$ :
$$
\bar{X}-\bar{Y}>t_{m+n-2}(\alpha) S_p \sqrt{\frac{1}{m}+\frac{1}{n}} \Rightarrow \text { reject } H_0
$$
## Arbitrary Unknown Variances: Approximate $t$-test
If the unknown variances cannot be assumed to be equal, the above method is not applicable. However, we can still estimate the variances using their corresponding sample variances, then we can construct the so called Welch Statistic:
$$W=\frac{\bar{X}-\bar{Y}}{\sqrt{S^2_x/m+S^2_y/n}}$$
In general the distribution of $W$ under $H_0:\mu_x=\mu_y$ is not a $t$-distribution, but it can be approximated as such
$$W\approx t_\nu$$
where $\nu$ is the "effective" number of degrees of freedom given by
$$\nu=\frac{(S^2_x/m+S^2_y/n)^2}{(S^2_x/m)^2/(m-1)+(S^2_y/n)^2(n-1)}$$
So for any hypothesis testing we can thus test using this approximated $t$-distribution.
# Comparing Variances: $F$-test
## Known Means
If the means are known then it is natural to base our testing on the variance estimators.
$$
\hat{\sigma}_x^2=\frac{1}{m} \sum_{i=1}^m\left(X_i-\mu_x\right)^2 , \quad \hat{\sigma}_y^2=\frac{1}{n} \sum_{i=1}^m\left(Y_j-\mu_y\right)^2 .
$$
Then according to Student's theorem,
$$
\frac{m \hat{\sigma}_x^2}{\sigma_x^2} \sim \chi_m^2, \quad \frac{n \hat{\sigma}_y^2}{\sigma_y^2} \sim \chi_n^2
$$
Furthermore, since $\hat{\sigma}_x^2$ and $\hat{\sigma}_y^2$ are independent (as functions of independent samples $\boldsymbol{X}$ and $\boldsymbol{Y}$ ), we can construct the following statistic which follows an $F$-distribution

$$
V=\frac{\left(m \hat{\sigma}_x^2 / \sigma_x^2\right) / m}{\left(n \hat{\sigma}_y^2 / \sigma_y^2\right) / n}=\frac{\hat{\sigma}_x^2 / \sigma_x^2}{\hat{\sigma}_y^2 / \sigma_y^2} \sim F_{m, n},
$$
In particular, under the null hypothesis $H_0: \sigma_x^2=\sigma_y^2$, we get
$$
V=\frac{\hat{\sigma}_x^2}{\hat{\sigma}_y^2} \sim F_{m, n}
$$
Then, we have the following tests:
- $H_0: \sigma_x^2=\sigma_y^2$ vs. $H_1: \sigma_x^2 \neq \sigma_y^2$.
$$
\frac{\hat{\sigma}_x^2}{\hat{\sigma}_y^2}>F_{m, n}(\alpha / 2) \text { or } \frac{\hat{\sigma}_x^2}{\hat{\sigma}_y^2}<F_{m, n}(1-\alpha / 2) \Rightarrow \text { reject } H_0
$$
- $H_0: \sigma_x^2 \leq \sigma_y^2$ vs. $H_1: \sigma_x^2>\sigma_y^2$ :
$$
\frac{\hat{\sigma}_x^2}{\hat{\sigma}_y^2}>F_{m, n}(\alpha) \Rightarrow \text { reject } H_0
$$
- $H_0: \sigma_x^2 \geq \sigma_y^2$ vs. $H_1: \sigma_x^2<\sigma_y^2$ :
$$
\frac{\hat{\sigma}_x^2}{\hat{\sigma}_y^2}<F_{m, n}(1-\alpha) \Rightarrow \text { reject } H_0
$$
## Unknown Means
In this case, we follow a very similar methodology. We can use sample variances to estimate the real variances of the 2 samples and in the same manner use their $\chi^2$-distributions. We can then construct yet another $F$-distribution in the same manner as the previous section.
$$
S_x^2=\frac{1}{m-1} \sum_{i=1}^m\left(X_i-\bar{X}\right)^2, \quad S_y^2=\frac{1}{n-1} \sum_{j=1}^n\left(Y_j-\bar{Y}\right)^2,
$$
$$
\frac{(m-1) S_x^2}{\sigma_x^2} \sim \chi_{m-1}^2, \quad \frac{(n-1) S_y^2}{\sigma_y^2} \sim \chi_{n-1}^2
$$
$$
V=\frac{S_x^2}{S_y^2} \sim F_{m-1, n-1}
$$
Then, we have the following tests:
- $H_0: \sigma_x^2=\sigma_y^2$ vs. $H_1: \sigma_x^2 \neq \sigma_y^2$ :
$$
\frac{S_x^2}{S_y^2}>F_{m-1, n-1}(\alpha / 2) \text { or } \frac{S_x^2}{S_y^2}<F_{m-1, n-1}(1-\alpha / 2) \Rightarrow \text { reject } H_0
$$
- $H_0: \sigma_x^2 \leq \sigma_y^2$ vs. $H_1: \sigma_x^2>\sigma_y^2$ :
$$
\frac{S_x^2}{S_y^2}>F_{m-1, n-1}(\alpha) \Rightarrow \text { reject } H_0
$$
- $H_0: \sigma_x^2 \geq \sigma_y^2$ vs. $H_1: \sigma_x^2<\sigma_y^2$ :
$$
\frac{S_x^2}{S_y^2}<F_{m-1, n-1}(1-\alpha) \Rightarrow \text { reject } H_0
$$
