In our previous sections, one of the assumptions made was that the two samples used are independent, but there are many situations where the samples are apparently not, for instance the data may be collected from twins, married couples or pairs of measurements on the same individuals (before and after), etc...

In this case then we would expect pairs of such measurements to be similar which violates the independence assumption needed for a 2 sample $z$-test or $t$-test. To do hypothesis testing on such samples we can use paired tests. 

The idea is to take the difference of each pair of observations and then deal with the resulting single sample, note that the sample sizes must match.
$$D_i=X_i-Y_i$$
Specifically suppose we have $X_1,...,X_n\sim N(\mu_x,\sigma^2_x)$ and $Y_1,...,Y_n\sim N(\mu_y,\sigma^2_y)$ with matched pairs $(X_i,Y_i)$. It is then natural to look at the distribution of the difference. When $X_i$ and $Y_i$ were independent we know that $D_i \sim N(\mu_x-\mu_y,\sigma^2_x+\sigma^2_y)$. However now that they can't be assumed to be independent, we still have $E[D_i]=\mu_x-\mu_y$, but the variance of $D_i$ will be different, possibly affected by correlation between $X_i$ and $Y_i$. Then we can model $D_i$ as a normal distribution with mean $\mu_d=\mu_x-\mu_y$ and some variance $\sigma^2_d$:
$$D_i\sim N(\mu_d,\sigma^2_d)$$
Then this reduces down to the case of known mean and known/unknown variance for a single sample, so we can use the $z$-test and $t$-test as usual.
# Advantages and Disadvantages of Paired Tests
Doing tests in such a manner may cause some loss of information because tests based on matched pairs would halve the number of observations available for testing. Thus, we should not use the differences if there are no genuinely matched pairs. 

A strong advantage of paired tests is that they overcome the problem of possible dependence within pairs, which would make it inappropriate to use two sample tests based on independence. 

Another advantage is that the variance $\sigma^2_d$ of the differences is typically smaller than the sum of variances $\sigma^2_x$ and $\sigma^2_y$ which wouldn't be the case were the samples independent. In turn, this gives us a smaller standard error and thus more precise inference. So a matched pairs design can reach the desired level of precision with fewer data points than a comparable design using two independent samples. 

Another important use of matched pairs is in reducing the bias in the study design. For instance in a medical study on some new drug, it is impossible to perfectly match patients based on age, sex, health etc... Instead an alternative experiment design called crossover design can be used where each treatment is observed for each individual subject. So a subject gets treated with the drug, and then with a placebo. This way we can remove potential bias from lurking unknown variables.