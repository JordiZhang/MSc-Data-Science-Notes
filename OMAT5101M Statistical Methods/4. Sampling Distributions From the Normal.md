# Pearson's $\chi^2$-Distribution
Let $X_1,...,X_\nu$ be independent and identically distributed random variables with standard normal distribution $N(0,1)$. Then we define the following random variable
$$Y=\sum_{i=1}^\nu X_i^2$$
Then $Y$ follows the $\chi^2$ distribution with $\nu$ degrees of freedom
$$Y\sim \chi^2_\nu$$
With probability density, mean and variance: 
$$f_Y(x)=\frac{x^{(\nu/2)-1}e^{-x/2}}{2^{\nu/2}\Gamma(\nu/2)},\qquad x>0$$
Where $\Gamma(\alpha)$ is the gamma function, continuous version of the factorial.
$$E[Y]=\nu,\qquad Var(Y)=2\nu$$
# Student's $t$-Distribution
Let $X$ and $Y$ be independent random variables with distributions $X\sim N(0,1)$ and $Y\sim \chi^2_\nu$. Then we define the following random variable
$$T=\frac{X}{\sqrt{Y/\nu}}$$
Then $T$ follows the $t$-distribution with $\nu$ degrees of freedom
$$T\sim t_\nu$$
With probability density, mean and variance:
$$f_T(x)=\frac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\pi\nu}\Gamma(\frac{\nu}{2})}\left(1+\frac{x^2}{\nu}\right)^{-(\nu+1)/2},\qquad x\in \mathbb{R}$$
$$E[T]=0\quad [\text{for }\nu>1],\qquad Var(T)=\frac{\nu}{\nu-2}\quad [\text{for }\nu>2]$$
# Fisher's $F$-Distribution
Let $Y_1$ and $Y_2$ be independent random variables with $\chi^2$-distributions $Y_1\sim\chi^2_{\nu_1}$ and $Y_2\sim\chi^2_{\nu_2}$. Then we define the following random variable
$$V=\frac{Y_1/\nu_1}{Y_2/\nu_2}$$
Then $V$ follows the $F$-distribution with $\nu_1$ and $\nu_2$ degrees of freedom
$$V\sim F_{\nu_1,\nu_2}$$
Note that the order of $\nu_1$ and $\nu_2$ matters as the first is the numerator and the second the denominator. So for example
$$V^{-1}\sim F_{\nu_2,\nu_1}$$
With probability density, mean and variance:
$$f_V(x)=\frac{1}{xB(\frac{\nu_1}{2},\frac{\nu_2}{2})}\sqrt{\frac{(\nu_1x)^{\nu_1}\nu_2^{\nu_2}}{(\nu_1x+\nu_2)^{\nu_1+\nu_2}}},\qquad x>0$$
$$E[V]=\frac{\nu_2}{\nu_2-2}\quad [\text{for }\nu_2>2],\qquad Var(V)=\frac{2\nu_2^2(\nu_1+\nu_2-2)}{\nu_1(\nu_2-2)^2(\nu_2-4)}\quad [\text{for }\nu_2>4]$$
# Student's Theorem
Let $X_1,...,X_n$ be independent random variables with common normal distribution $X_i\sim N(\mu,\sigma^2)$. Consider the sample mean and sample variance:
$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i,\qquad S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X})^2$$
Then,
- $\bar{X}\sim N(\mu,\sigma^2/n)$
- $(n-1)S^2/\sigma^2\sim \chi^2_{n-1}$
- $\bar{X}$ and $S^2$ are independent as random variables, rather surprising since we have $\bar{X}$ in $S^2$, but this actually is true and we have some evidence of it since they are uncorrelated, so zero covariance
## Corollary 1
$$T=\frac{\sqrt{n}(\bar{X}-\mu)}{S}\sim t_{n-1}$$
## Corollary 2
Let $X_1,...,X_m$ and $Y_1,...,Y_n$ be independent random variables with normal distributions $X_i\sim N(\mu_x,\sigma^2)$ and $Y_j\sim N(\mu_y, \sigma^2)$, with same variance but possibly different means. We consider their corresponding sample means and variances:
$$\bar{X}=\frac{1}{m}\sum_{i=1}^mX_i,\qquad S^2_x=\frac{1}{m-1}\sum_{i=1}^m(X_i-\bar{X})^2$$
$$\bar{Y}=\frac{1}{n}\sum_{j=1}^nY_j,\qquad S^2_y=\frac{1}{n-1}\sum_{j=1}^n(Y_j-\bar{Y})^2$$
Then the following statements hold:
- The ratio of sample variances has an $F$-distribution with $(m-1,n-1)$ degrees of freedom
$$\frac{S^2_x}{S^2_y}\sim F_{m-1,n-1}$$
- A pooled sample variance defined by
$$S^2_p=\frac{(m-1)S^2_x+(n-1)S^2_y}{m+n-2}=\frac{\sum^m_{i=1}(X_i-\bar{X})^2+\sum^n_{j=1}(Y_j-\bar{Y})^2}{m+n-2}$$
  has a $\chi^2$-distribution with $(m+n-2)$ degrees of freedom
$$\frac{(m+n-2)S^2_p}{\sigma^2}\sim \chi^2_{m+n-2}$$
  In particular, $S^2_p$ is an unbiased estimator of the variance $\sigma^2$:
$$E[S^2_p]=\sigma^2$$
- The difference of the sample means has a normal distribution
$$\bar{X}-\bar{Y}\sim N\left(\mu_x-\mu_y,\sigma^2\left(\frac{1}{m}+\frac{1}{n}\right)\right)$$
- The following ratio has a $t$-distribution with $m+n-2$ degrees of freedom:
$$\frac{\bar{X}-\bar{Y}-(\mu_x-\mu_y)}{S_p\sqrt{\frac{1}{m}+\frac{1}{n}}}\sim t_{m+n-2}$$
  In particular if $\mu_x=\mu_y$ then,
$$\frac{\bar{X}-\bar{Y}}{S_p\sqrt{\frac{1}{m}+\frac{1}{n}}}\sim t_{m+n-2}$$