# Pearson Correlation
$$\rho_{i_x i_y}=\frac{\sum_{i=1}^n\left(x_i-\bar{x}\right)\left(y_i-\bar{y}\right)}{\sqrt{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2} \sqrt{\sum_{i=1}^n\left(y_i-\bar{y}\right)^2}}$$
# Linear Regression
We model a linear relationship as 
$$y=\alpha + \beta x $$
With $\alpha$ being the intercepts and $\beta$ the gradients. This can of course be extended into multivariate linear regression by having $\alpha$, $\beta$ and $x$ be vectors.

As is usual, we define a loss function. In this case it is natural to use the MSE, which simply measures the deviation of the points from the fitted line. 
$$L(\alpha,\beta)=\frac{1}{n}\sum_{i=1}^n(y_i-(\alpha +\beta x_i))^2$$
Minimizing the loss leads us to the following best parameters:
$$\hat{\alpha}=\bar{y}-\hat{\beta}\bar{x},\qquad \hat{\beta}=\frac{s_{xy}}{s_x^2}$$